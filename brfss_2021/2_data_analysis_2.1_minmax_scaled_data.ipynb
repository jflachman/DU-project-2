{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Analysis\n",
    "\n",
    "- This file differs from [2_data_analysis_1_base_data.ipynb](2_data_analysis_1_base_data.ipynb) in that it:\n",
    "    - scales the base cleaned data created in [1_data_cleaning.ipynb](1_data_cleaning.ipynb).\n",
    "\n",
    "Source dataset: 247076 rows × 37 columns\n",
    "Processed and analyzed dataset: 247076 rows × 37 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:47.535438Z",
     "iopub.status.busy": "2024-06-10T23:00:47.535215Z",
     "iopub.status.idle": "2024-06-10T23:00:48.639303Z",
     "shell.execute_reply": "2024-06-10T23:00:48.638243Z"
    }
   },
   "outputs": [],
   "source": [
    "# package imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import config\n",
    "import time\n",
    "\n",
    "sys.path.insert(1, config.package_path)\n",
    "import ml_analysis as mlanlys\n",
    "import ml_clean_feature as mlclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.642024Z",
     "iopub.status.busy": "2024-06-10T23:00:48.641594Z",
     "iopub.status.idle": "2024-06-10T23:00:48.644958Z",
     "shell.execute_reply": "2024-06-10T23:00:48.644298Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read the cleaned dataset from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.647808Z",
     "iopub.status.busy": "2024-06-10T23:00:48.647358Z",
     "iopub.status.idle": "2024-06-10T23:00:48.658758Z",
     "shell.execute_reply": "2024-06-10T23:00:48.658109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:                        2021\n",
      "Clean File:                  data/brfss_2021_clean.parquet.gzip\n",
      "Performance Report:          reports/performance_report.pkl\n",
      "Detailed Performance Report: reports/2.1_minmaxscaler_dataset_detailed_performance_report.txt\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to Config Settings\n",
    "importlib.reload(config)\n",
    "\n",
    "# BE SURE TO UPDATE THE LABEL FOR THIS ANALYSIS\n",
    "# #############################\n",
    "dataset_label = '2.1 MinMaxScaler Dataset'\n",
    "# #############################\n",
    "\n",
    "year                        = config.year\n",
    "\n",
    "clean_file                  = config.clean_file\n",
    "performance_report          = config.performance_report\n",
    "\n",
    "report_path                 = config.report_path\n",
    "file_label                  = dataset_label.lower().replace(' ','_')\n",
    "detailed_performance_report = report_path + file_label + '_detailed_performance_report.txt'\n",
    "\n",
    "print(f\"Year:                        {year}\")\n",
    "print(f\"Clean File:                  {clean_file}\")\n",
    "print(f\"Performance Report:          {performance_report}\")\n",
    "print(f\"Detailed Performance Report: {detailed_performance_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.661101Z",
     "iopub.status.busy": "2024-06-10T23:00:48.660689Z",
     "iopub.status.idle": "2024-06-10T23:00:48.883570Z",
     "shell.execute_reply": "2024-06-10T23:00:48.882929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read final cleaned dataset from parquet file\n",
    "df = pd.read_parquet(clean_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.886324Z",
     "iopub.status.busy": "2024-06-10T23:00:48.885828Z",
     "iopub.status.idle": "2024-06-10T23:00:48.889009Z",
     "shell.execute_reply": "2024-06-10T23:00:48.888372Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes_labels = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.891489Z",
     "iopub.status.busy": "2024-06-10T23:00:48.890862Z",
     "iopub.status.idle": "2024-06-10T23:00:48.897228Z",
     "shell.execute_reply": "2024-06-10T23:00:48.896205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247076, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare the dataset for analysis\n",
    "\n",
    "- Split the dataset into features and labels.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.899919Z",
     "iopub.status.busy": "2024-06-10T23:00:48.899531Z",
     "iopub.status.idle": "2024-06-10T23:00:48.926631Z",
     "shell.execute_reply": "2024-06-10T23:00:48.925769Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:48.929353Z",
     "iopub.status.busy": "2024-06-10T23:00:48.928867Z",
     "iopub.status.idle": "2024-06-10T23:00:49.161317Z",
     "shell.execute_reply": "2024-06-10T23:00:49.160384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  False\n",
      "**Operation:scaler  minmax\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing MinMaxScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  none\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (247076, 37)  Data:4, X_train:185307, y_train:185307, X_test:61769, y_test:61769\n",
      "ValueCounts:   y_train: len:2   0: 156420   1:  4239\n",
      "ValueCounts:   y_test : len:2   0:  51969   1:  1415\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "target = 'diabetes'\n",
    "# Dictionary defining modification to be made to the base dataset\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  False,\n",
    "                    'scaler'            : 'minmax', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'none'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:49.163900Z",
     "iopub.status.busy": "2024-06-10T23:00:49.163587Z",
     "iopub.status.idle": "2024-06-10T23:00:49.174188Z",
     "shell.execute_reply": "2024-06-10T23:00:49.173494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (247076, 37)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    208389\n",
      "2.0     33033\n",
      "1.0      5654\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modified Dataframe\n",
      "------------------\n",
      "df_modified.shape: (247076, 37)\n",
      "df_modified[diabetes].value_counts:  diabetes\n",
      "0.0    208389\n",
      "2.0     33033\n",
      "1.0      5654\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"Original Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")\n",
    "\n",
    "print(f\"\\nModified Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df_modified.shape: {df_modified.shape}\")\n",
    "print(f\"df_modified[{target}].value_counts:  {df_modified[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:49.176966Z",
     "iopub.status.busy": "2024-06-10T23:00:49.176381Z",
     "iopub.status.idle": "2024-06-10T23:00:49.183765Z",
     "shell.execute_reply": "2024-06-10T23:00:49.182794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (247076, 37)  Data:4, X_train:185307, y_train:185307, X_test:61769, y_test:61769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    156420\n",
       "2.0     24648\n",
       "1.0      4239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = data\n",
    "print(f\"Dataframe: {df_modified.shape}  Data:{len(data)}, X_train:{len(X_train)}, y_train:{len(y_train)}, X_test:{len(X_test)}, y_test:{len(y_test)}\")\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:49.186642Z",
     "iopub.status.busy": "2024-06-10T23:00:49.185943Z",
     "iopub.status.idle": "2024-06-10T23:00:49.191863Z",
     "shell.execute_reply": "2024-06-10T23:00:49.191077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    51969\n",
       "2.0     8385\n",
       "1.0     1415\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run initial Tests and get k_value\n",
    "\n",
    "**From step 2:**  Data = [X_train_modified, X_test_modified, y_train_modified, y_test]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:49.194113Z",
     "iopub.status.busy": "2024-06-10T23:00:49.193915Z",
     "iopub.status.idle": "2024-06-10T23:00:49.211829Z",
     "shell.execute_reply": "2024-06-10T23:00:49.210711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ml_analysis' from '/mnt/c/ML/DU/repos/projects/project-2/DU-project-2-2015/brfss_2021/../pkgs/ml_analysis.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "# Determine the k_value\n",
    "# mlanlys.knn_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** From the knn plot above, pick a k-value of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Run the Analysis\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Run Times\n",
    "\n",
    "-  Base dataset (247076 rows × 37 columns):\n",
    "\n",
    "| Model | Run Time |\n",
    "| ----- | -------- |\n",
    "| test_model(SVC(kernel='linear'), data)                          | Aborted >35min (Data too large, consider for RandomUndersampling dataset) |\n",
    "| test_model(KNeighborsClassifier(n_neighbors=k_value), data)     | 247.13 seconds |\n",
    "| test_model(tree.DecisionTreeClassifier(), data)                 |   3.89 seconds |\n",
    "| test_model(RandomForestClassifier(), data)                      |  60.94 seconds |\n",
    "| test_model(ExtraTreesClassifier(random_state=1), data)          |  58.54 seconds |\n",
    "| test_model(GradientBoostingClassifier(random_state=1), data)    | 115.21 seconds |\n",
    "| test_model(AdaBoostClassifier(random_state=1), data)            |  11.91 seconds |\n",
    "| test_model(LogisticRegression(), data)                          |   4.90 seconds |\n",
    "| **Total** w/o SVC| 502.52 seconds / **8:23 minutes** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:49.215953Z",
     "iopub.status.busy": "2024-06-10T23:00:49.215634Z",
     "iopub.status.idle": "2024-06-10T23:09:54.657948Z",
     "shell.execute_reply": "2024-06-10T23:09:54.656093Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload any changes to nlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "k_value = 3\n",
    "\n",
    "#### COMMENT OUT ONE OF THE FOLLOWING SECTIONS\n",
    "\n",
    "## SECTION 1\n",
    "# Capture stdout & stderr into two strings: osc.stdout and osc.stderr that contain the output from the function\n",
    "# -- This allows the output to be printed here or to a file or both.\n",
    "\n",
    "with mlanlys.OutStreamCapture() as osc:\n",
    "    performance_summary = mlanlys.run_classification_models(data, k_value)\n",
    "#    performance_summary = mlanlys.run_classification_models_test(data, k_value)\n",
    "\n",
    "## <OR>\n",
    "## SECTION 2\n",
    "\n",
    "# performance_summary = mlanlys.run_classification_models(data, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:09:54.669808Z",
     "iopub.status.busy": "2024-06-10T23:09:54.668233Z",
     "iopub.status.idle": "2024-06-10T23:09:54.674939Z",
     "shell.execute_reply": "2024-06-10T23:09:54.673783Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT if using SECTION 1 in the previous step\n",
    "# print(osc.stdout)\n",
    "\n",
    "# Add code to print osc.stdout to a file if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.1 Archive Performance Summary\n",
    "\n",
    "- For use in Project-2 Performance Summary Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:09:54.680018Z",
     "iopub.status.busy": "2024-06-10T23:09:54.679533Z",
     "iopub.status.idle": "2024-06-10T23:09:54.720408Z",
     "shell.execute_reply": "2024-06-10T23:09:54.718592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file reports/performance_report.pkl exists.\n"
     ]
    }
   ],
   "source": [
    "# performance_summary is a dataframe of performance statistics\n",
    "\n",
    "# Add the dataset label as the first column in performance_summary\n",
    "dataset_column = pd.Series([dataset_label] * len(performance_summary), name=dataset_label)\n",
    "performance_summary.insert(0, 'new_column', dataset_column)\n",
    "\n",
    "analysis_perf_summary = { 'dataset_size': list(df.shape), 'report': performance_summary}\n",
    "\n",
    "# Performance_report is a file containing all the performance summary statistics\n",
    "if os.path.exists(performance_report):\n",
    "    print(f\"The file {performance_report} exists.\")\n",
    "    # Load Performance Report\n",
    "    with open(performance_report, 'rb') as file: perf_report = pickle.load(file)\n",
    "else:\n",
    "    print(f\"The file {performance_report} does not exist.\")\n",
    "    perf_report = {}\n",
    "    \n",
    "perf_report[dataset_label] = analysis_perf_summary\n",
    "\n",
    "# Save Performance Report\n",
    "with open(performance_report, 'wb') as file: pickle.dump(perf_report, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Archive the Performance Detailed Statistics Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:09:54.726152Z",
     "iopub.status.busy": "2024-06-10T23:09:54.724821Z",
     "iopub.status.idle": "2024-06-10T23:09:54.745331Z",
     "shell.execute_reply": "2024-06-10T23:09:54.743525Z"
    }
   },
   "outputs": [],
   "source": [
    "# osc.stdout contains the details of the performance statistics\n",
    "\n",
    "with open(detailed_performance_report, \"w\") as file:\n",
    "    file.write(osc.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Performance Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:09:54.751106Z",
     "iopub.status.busy": "2024-06-10T23:09:54.750635Z",
     "iopub.status.idle": "2024-06-10T23:09:54.787515Z",
     "shell.execute_reply": "2024-06-10T23:09:54.786100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "Performance Summary for: 2.1 MinMaxScaler Dataset\n",
      "******************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_column</th>\n",
       "      <th>model</th>\n",
       "      <th>slice</th>\n",
       "      <th>score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>Matthews Correlation Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.6195</td>\n",
       "      <td>0.6546</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.4059</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.2944</td>\n",
       "      <td>0.3089</td>\n",
       "      <td>0.3015</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.2312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.3886</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>0.7661</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.3839</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.1 MinMaxScaler Dataset</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.8654</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.2339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  new_column                       model  slice   score  \\\n",
       "0   2.1 MinMaxScaler Dataset        KNeighborsClassifier  Train  0.8853   \n",
       "1   2.1 MinMaxScaler Dataset        KNeighborsClassifier   Test  0.8178   \n",
       "2   2.1 MinMaxScaler Dataset      DecisionTreeClassifier  Train  1.0000   \n",
       "3   2.1 MinMaxScaler Dataset      DecisionTreeClassifier   Test  0.7673   \n",
       "4   2.1 MinMaxScaler Dataset      RandomForestClassifier  Train  1.0000   \n",
       "5   2.1 MinMaxScaler Dataset      RandomForestClassifier   Test  0.8469   \n",
       "6   2.1 MinMaxScaler Dataset        ExtraTreesClassifier  Train  1.0000   \n",
       "7   2.1 MinMaxScaler Dataset        ExtraTreesClassifier   Test  0.8448   \n",
       "8   2.1 MinMaxScaler Dataset  GradientBoostingClassifier  Train  0.8528   \n",
       "9   2.1 MinMaxScaler Dataset  GradientBoostingClassifier   Test  0.8480   \n",
       "10  2.1 MinMaxScaler Dataset          AdaBoostClassifier  Train  0.8501   \n",
       "11  2.1 MinMaxScaler Dataset          AdaBoostClassifier   Test  0.8467   \n",
       "12  2.1 MinMaxScaler Dataset          LogisticRegression  Train  0.8483   \n",
       "13  2.1 MinMaxScaler Dataset          LogisticRegression   Test  0.8445   \n",
       "\n",
       "    balanced_accuracy  roc_auc_score  Mean Squared Error  Accuracy  Precision  \\\n",
       "0              0.5048         0.9474              0.3930    0.9055     0.7245   \n",
       "1              0.3887         0.6195              0.6546    0.8386     0.3533   \n",
       "2              1.0000         1.0000              0.0000    1.0000     1.0000   \n",
       "3              0.4059         0.5696              0.7806    0.8057     0.2944   \n",
       "4              0.9997         1.0000              0.0001    1.0000     1.0000   \n",
       "5              0.3776         0.7585              0.5435    0.8681     0.5519   \n",
       "6              1.0000         1.0000              0.0000    1.0000     1.0000   \n",
       "7              0.3787         0.7488              0.5520    0.8657     0.5172   \n",
       "8              0.3929         0.8001              0.5203    0.8738     0.5736   \n",
       "9              0.3886         0.7906              0.5392    0.8687     0.5483   \n",
       "10             0.3972         0.7661              0.5310    0.8708     0.5348   \n",
       "11             0.3943         0.7583              0.5443    0.8670     0.5255   \n",
       "12             0.3839         0.7801              0.5380    0.8695     0.5287   \n",
       "13             0.3802         0.7777              0.5532    0.8654     0.5129   \n",
       "\n",
       "    Recall  F1-score  Specificity  False Positive Rate  \\\n",
       "0   0.4673    0.5681       0.9727               0.0273   \n",
       "1   0.2272    0.2766       0.9347               0.0653   \n",
       "2   1.0000    1.0000       1.0000               0.0000   \n",
       "3   0.3089    0.3015       0.8837               0.1163   \n",
       "4   0.9999    0.9999       1.0000               0.0000   \n",
       "5   0.1504    0.2364       0.9808               0.0192   \n",
       "6   1.0000    1.0000       1.0000               0.0000   \n",
       "7   0.1574    0.2413       0.9769               0.0231   \n",
       "8   0.1988    0.2953       0.9773               0.0227   \n",
       "9   0.1875    0.2794       0.9757               0.0243   \n",
       "10  0.2190    0.3107       0.9708               0.0292   \n",
       "11  0.2104    0.3005       0.9702               0.0298   \n",
       "12  0.1740    0.2618       0.9762               0.0238   \n",
       "13  0.1631    0.2475       0.9757               0.0243   \n",
       "\n",
       "    Matthews Correlation Coefficient  \n",
       "0                                NaN  \n",
       "1                             0.1964  \n",
       "2                                NaN  \n",
       "3                             0.1888  \n",
       "4                                NaN  \n",
       "5                             0.2381  \n",
       "6                                NaN  \n",
       "7                             0.2312  \n",
       "8                             0.2853  \n",
       "9                             0.2657  \n",
       "10                            0.2840  \n",
       "11                            0.2728  \n",
       "12                            0.2493  \n",
       "13                            0.2339  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the performance summary\n",
    "print(f\"******************************************\")\n",
    "print(f\"Performance Summary for: {dataset_label}\")\n",
    "print(f\"******************************************\")\n",
    "\n",
    "performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:09:54.792365Z",
     "iopub.status.busy": "2024-06-10T23:09:54.791922Z",
     "iopub.status.idle": "2024-06-10T23:09:54.799827Z",
     "shell.execute_reply": "2024-06-10T23:09:54.797258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Execution Time 546.15 seconds:\n"
     ]
    }
   ],
   "source": [
    "print(f\"Completed: Execution Time %s seconds:\" % round((time.time() - start_time),2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusions\n",
    "\n",
    "- A first glance at the summary, it appears that the Boosting models may have performed well with test/train scores were >.8 and similar in scale (<.02 delta).  However, the poor test confusion matrix and balanced accuracy highlight the overfitting.\n",
    "\n",
    "- The Base Cleaned data is overfit as indicated by:\n",
    "    - Poor confusion matrix on the detailed report for test sets on all models\n",
    "    - Low balanced accuracy as compared to the model score (less than 50%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
