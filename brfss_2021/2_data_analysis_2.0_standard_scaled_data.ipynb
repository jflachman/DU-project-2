{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Analysis\n",
    "\n",
    "- This file differs from [2_data_analysis_1_base_data.ipynb](2_data_analysis_1_base_data.ipynb) in that it:\n",
    "    - scales the base cleaned data created in [1_data_cleaning.ipynb](1_data_cleaning.ipynb).\n",
    "\n",
    "Source dataset: 247076 rows × 37 columns\n",
    "Processed and analyzed dataset: 247076 rows × 37 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:55.062677Z",
     "iopub.status.busy": "2024-06-10T22:52:55.062319Z",
     "iopub.status.idle": "2024-06-10T22:52:57.097098Z",
     "shell.execute_reply": "2024-06-10T22:52:57.095307Z"
    }
   },
   "outputs": [],
   "source": [
    "# package imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import config\n",
    "import time\n",
    "\n",
    "sys.path.insert(1, config.package_path)\n",
    "import ml_analysis as mlanlys\n",
    "import ml_clean_feature as mlclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.102841Z",
     "iopub.status.busy": "2024-06-10T22:52:57.101280Z",
     "iopub.status.idle": "2024-06-10T22:52:57.108045Z",
     "shell.execute_reply": "2024-06-10T22:52:57.106968Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read the cleaned dataset from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.111872Z",
     "iopub.status.busy": "2024-06-10T22:52:57.111512Z",
     "iopub.status.idle": "2024-06-10T22:52:57.134930Z",
     "shell.execute_reply": "2024-06-10T22:52:57.133134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:                        2021\n",
      "Clean File:                  data/brfss_2021_clean.parquet.gzip\n",
      "Performance Report:          reports/performance_report.pkl\n",
      "Detailed Performance Report: reports/2.0_standardscaler_dataset_detailed_performance_report.txt\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to Config Settings\n",
    "importlib.reload(config)\n",
    "\n",
    "# BE SURE TO UPDATE THE LABEL FOR THIS ANALYSIS\n",
    "# #############################\n",
    "dataset_label = '2.0 StandardScaler Dataset'\n",
    "# #############################\n",
    "\n",
    "year                        = config.year\n",
    "\n",
    "clean_file                  = config.clean_file\n",
    "performance_report          = config.performance_report\n",
    "\n",
    "report_path                 = config.report_path\n",
    "file_label                  = dataset_label.lower().replace(' ','_')\n",
    "detailed_performance_report = report_path + file_label + '_detailed_performance_report.txt'\n",
    "\n",
    "print(f\"Year:                        {year}\")\n",
    "print(f\"Clean File:                  {clean_file}\")\n",
    "print(f\"Performance Report:          {performance_report}\")\n",
    "print(f\"Detailed Performance Report: {detailed_performance_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.140546Z",
     "iopub.status.busy": "2024-06-10T22:52:57.139393Z",
     "iopub.status.idle": "2024-06-10T22:52:57.556500Z",
     "shell.execute_reply": "2024-06-10T22:52:57.553957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read final cleaned dataset from parquet file\n",
    "df = pd.read_parquet(clean_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.564156Z",
     "iopub.status.busy": "2024-06-10T22:52:57.562670Z",
     "iopub.status.idle": "2024-06-10T22:52:57.571733Z",
     "shell.execute_reply": "2024-06-10T22:52:57.569848Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes_labels = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.578123Z",
     "iopub.status.busy": "2024-06-10T22:52:57.577484Z",
     "iopub.status.idle": "2024-06-10T22:52:57.591197Z",
     "shell.execute_reply": "2024-06-10T22:52:57.589071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247076, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare the dataset for analysis\n",
    "\n",
    "- Split the dataset into features and labels.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.597980Z",
     "iopub.status.busy": "2024-06-10T22:52:57.596344Z",
     "iopub.status.idle": "2024-06-10T22:52:57.655172Z",
     "shell.execute_reply": "2024-06-10T22:52:57.654103Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:57.659133Z",
     "iopub.status.busy": "2024-06-10T22:52:57.658683Z",
     "iopub.status.idle": "2024-06-10T22:52:58.305264Z",
     "shell.execute_reply": "2024-06-10T22:52:58.303899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  False\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  none\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (247076, 37)  Data:4, X_train:185307, y_train:185307, X_test:61769, y_test:61769\n",
      "ValueCounts:   y_train: len:2   0: 156260   1:  4207\n",
      "ValueCounts:   y_test : len:2   0:  52129   1:  1447\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "target = 'diabetes'\n",
    "# Dictionary defining modification to be made to the base dataset\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  False,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'none'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:58.310725Z",
     "iopub.status.busy": "2024-06-10T22:52:58.309963Z",
     "iopub.status.idle": "2024-06-10T22:52:58.327024Z",
     "shell.execute_reply": "2024-06-10T22:52:58.325918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (247076, 37)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    208389\n",
      "2.0     33033\n",
      "1.0      5654\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modified Dataframe\n",
      "------------------\n",
      "df_modified.shape: (247076, 37)\n",
      "df_modified[diabetes].value_counts:  diabetes\n",
      "0.0    208389\n",
      "2.0     33033\n",
      "1.0      5654\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"Original Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")\n",
    "\n",
    "print(f\"\\nModified Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df_modified.shape: {df_modified.shape}\")\n",
    "print(f\"df_modified[{target}].value_counts:  {df_modified[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:58.330591Z",
     "iopub.status.busy": "2024-06-10T22:52:58.330230Z",
     "iopub.status.idle": "2024-06-10T22:52:58.343453Z",
     "shell.execute_reply": "2024-06-10T22:52:58.342427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (247076, 37)  Data:4, X_train:185307, y_train:185307, X_test:61769, y_test:61769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    156260\n",
       "2.0     24840\n",
       "1.0      4207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = data\n",
    "print(f\"Dataframe: {df_modified.shape}  Data:{len(data)}, X_train:{len(X_train)}, y_train:{len(y_train)}, X_test:{len(X_test)}, y_test:{len(y_test)}\")\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:58.346639Z",
     "iopub.status.busy": "2024-06-10T22:52:58.346298Z",
     "iopub.status.idle": "2024-06-10T22:52:58.353397Z",
     "shell.execute_reply": "2024-06-10T22:52:58.352468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    52129\n",
       "2.0     8193\n",
       "1.0     1447\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run initial Tests and get k_value\n",
    "\n",
    "**From step 2:**  Data = [X_train_modified, X_test_modified, y_train_modified, y_test]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:58.357539Z",
     "iopub.status.busy": "2024-06-10T22:52:58.357244Z",
     "iopub.status.idle": "2024-06-10T22:52:58.373417Z",
     "shell.execute_reply": "2024-06-10T22:52:58.372636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ml_analysis' from '/mnt/c/ML/DU/repos/projects/project-2/DU-project-2-2015/brfss_2021/../pkgs/ml_analysis.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "# Determine the k_value\n",
    "# mlanlys.knn_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** From the knn plot above, pick a k-value of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Run the Analysis\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Run Times\n",
    "\n",
    "-  Base dataset (247076 rows × 37 columns):\n",
    "\n",
    "| Model | Run Time |\n",
    "| ----- | -------- |\n",
    "| test_model(SVC(kernel='linear'), data)                          | Aborted >35min (Data too large, consider for RandomUndersampling dataset) |\n",
    "| test_model(KNeighborsClassifier(n_neighbors=k_value), data)     | 247.13 seconds |\n",
    "| test_model(tree.DecisionTreeClassifier(), data)                 |   3.89 seconds |\n",
    "| test_model(RandomForestClassifier(), data)                      |  60.94 seconds |\n",
    "| test_model(ExtraTreesClassifier(random_state=1), data)          |  58.54 seconds |\n",
    "| test_model(GradientBoostingClassifier(random_state=1), data)    | 115.21 seconds |\n",
    "| test_model(AdaBoostClassifier(random_state=1), data)            |  11.91 seconds |\n",
    "| test_model(LogisticRegression(), data)                          |   4.90 seconds |\n",
    "| **Total** w/o SVC| 502.52 seconds / **8:23 minutes** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T22:52:58.376474Z",
     "iopub.status.busy": "2024-06-10T22:52:58.376191Z",
     "iopub.status.idle": "2024-06-10T23:00:45.509594Z",
     "shell.execute_reply": "2024-06-10T23:00:45.507644Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload any changes to nlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "k_value = 3\n",
    "\n",
    "#### COMMENT OUT ONE OF THE FOLLOWING SECTIONS\n",
    "\n",
    "## SECTION 1\n",
    "# Capture stdout & stderr into two strings: osc.stdout and osc.stderr that contain the output from the function\n",
    "# -- This allows the output to be printed here or to a file or both.\n",
    "\n",
    "with mlanlys.OutStreamCapture() as osc:\n",
    "    performance_summary = mlanlys.run_classification_models(data, k_value)\n",
    "#    performance_summary = mlanlys.run_classification_models_test(data, k_value)\n",
    "\n",
    "## <OR>\n",
    "## SECTION 2\n",
    "\n",
    "# performance_summary = mlanlys.run_classification_models(data, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:45.516119Z",
     "iopub.status.busy": "2024-06-10T23:00:45.515439Z",
     "iopub.status.idle": "2024-06-10T23:00:45.520749Z",
     "shell.execute_reply": "2024-06-10T23:00:45.519404Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT if using SECTION 1 in the previous step\n",
    "# print(osc.stdout)\n",
    "\n",
    "# Add code to print osc.stdout to a file if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.1 Archive Performance Summary\n",
    "\n",
    "- For use in Project Performance Summary Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:45.524509Z",
     "iopub.status.busy": "2024-06-10T23:00:45.524166Z",
     "iopub.status.idle": "2024-06-10T23:00:45.569833Z",
     "shell.execute_reply": "2024-06-10T23:00:45.568037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file reports/performance_report.pkl exists.\n"
     ]
    }
   ],
   "source": [
    "# performance_summary is a dataframe of performance statistics\n",
    "\n",
    "# Add the dataset label as the first column in performance_summary\n",
    "dataset_column = pd.Series([dataset_label] * len(performance_summary), name=dataset_label)\n",
    "performance_summary.insert(0, 'new_column', dataset_column)\n",
    "\n",
    "analysis_perf_summary = { 'dataset_size': list(df.shape), 'report': performance_summary}\n",
    "\n",
    "# Performance_report is a file containing all the performance summary statistics\n",
    "if os.path.exists(performance_report):\n",
    "    print(f\"The file {performance_report} exists.\")\n",
    "    # Load Performance Report\n",
    "    with open(performance_report, 'rb') as file: perf_report = pickle.load(file)\n",
    "else:\n",
    "    print(f\"The file {performance_report} does not exist.\")\n",
    "    perf_report = {}\n",
    "    \n",
    "perf_report[dataset_label] = analysis_perf_summary\n",
    "\n",
    "# Save Performance Report\n",
    "with open(performance_report, 'wb') as file: pickle.dump(perf_report, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Archive the Performance Detailed Statistics Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:45.575722Z",
     "iopub.status.busy": "2024-06-10T23:00:45.574734Z",
     "iopub.status.idle": "2024-06-10T23:00:45.599847Z",
     "shell.execute_reply": "2024-06-10T23:00:45.597310Z"
    }
   },
   "outputs": [],
   "source": [
    "# osc.stdout contains the details of the performance statistics\n",
    "\n",
    "with open(detailed_performance_report, \"w\") as file:\n",
    "    file.write(osc.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Performance Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:45.605357Z",
     "iopub.status.busy": "2024-06-10T23:00:45.604858Z",
     "iopub.status.idle": "2024-06-10T23:00:45.635914Z",
     "shell.execute_reply": "2024-06-10T23:00:45.634621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "Performance Summary for: 2.0 StandardScaler Dataset\n",
      "******************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_column</th>\n",
       "      <th>model</th>\n",
       "      <th>slice</th>\n",
       "      <th>score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>Matthews Correlation Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.3901</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>0.3504</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.3812</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.5309</td>\n",
       "      <td>0.8716</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.5235</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.5251</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.5554</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.2792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.3971</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.5327</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.5243</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.2455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0 StandardScaler Dataset</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.5359</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    new_column                       model  slice   score  \\\n",
       "0   2.0 StandardScaler Dataset        KNeighborsClassifier  Train  0.8861   \n",
       "1   2.0 StandardScaler Dataset        KNeighborsClassifier   Test  0.8197   \n",
       "2   2.0 StandardScaler Dataset      DecisionTreeClassifier  Train  1.0000   \n",
       "3   2.0 StandardScaler Dataset      DecisionTreeClassifier   Test  0.7640   \n",
       "4   2.0 StandardScaler Dataset      RandomForestClassifier  Train  1.0000   \n",
       "5   2.0 StandardScaler Dataset      RandomForestClassifier   Test  0.8497   \n",
       "6   2.0 StandardScaler Dataset        ExtraTreesClassifier  Train  1.0000   \n",
       "7   2.0 StandardScaler Dataset        ExtraTreesClassifier   Test  0.8466   \n",
       "8   2.0 StandardScaler Dataset  GradientBoostingClassifier  Train  0.8521   \n",
       "9   2.0 StandardScaler Dataset  GradientBoostingClassifier   Test  0.8511   \n",
       "10  2.0 StandardScaler Dataset          AdaBoostClassifier  Train  0.8489   \n",
       "11  2.0 StandardScaler Dataset          AdaBoostClassifier   Test  0.8492   \n",
       "12  2.0 StandardScaler Dataset          LogisticRegression  Train  0.8472   \n",
       "13  2.0 StandardScaler Dataset          LogisticRegression   Test  0.8485   \n",
       "\n",
       "    balanced_accuracy  roc_auc_score  Mean Squared Error  Accuracy  Precision  \\\n",
       "0              0.5072         0.9485              0.3901    0.9063     0.7268   \n",
       "1              0.3909         0.6249              0.6447    0.8409     0.3504   \n",
       "2              1.0000         1.0000              0.0000    1.0000     1.0000   \n",
       "3              0.4032         0.5679              0.7947    0.8021     0.2809   \n",
       "4              0.9999         1.0000              0.0000    1.0000     1.0000   \n",
       "5              0.3812         0.7648              0.5309    0.8716     0.5542   \n",
       "6              1.0000         1.0000              0.0000    1.0000     1.0000   \n",
       "7              0.3800         0.7564              0.5430    0.8684     0.5121   \n",
       "8              0.3932         0.7983              0.5235    0.8729     0.5742   \n",
       "9              0.3924         0.7955              0.5251    0.8727     0.5554   \n",
       "10             0.3971         0.7644              0.5361    0.8692     0.5296   \n",
       "11             0.3985         0.7666              0.5327    0.8703     0.5256   \n",
       "12             0.3830         0.7782              0.5432    0.8681     0.5243   \n",
       "13             0.3850         0.7832              0.5359    0.8700     0.5295   \n",
       "\n",
       "    Recall  F1-score  Specificity  False Positive Rate  \\\n",
       "0   0.4823    0.5798       0.9719               0.0281   \n",
       "1   0.2335    0.2802       0.9338               0.0662   \n",
       "2   1.0000    1.0000       1.0000               0.0000   \n",
       "3   0.3155    0.2972       0.8765               0.1235   \n",
       "4   1.0000    1.0000       1.0000               0.0000   \n",
       "5   0.1623    0.2511       0.9800               0.0200   \n",
       "6   1.0000    1.0000       1.0000               0.0000   \n",
       "7   0.1622    0.2464       0.9764               0.0236   \n",
       "8   0.2001    0.2968       0.9770               0.0230   \n",
       "9   0.2000    0.2941       0.9755               0.0245   \n",
       "10  0.2195    0.3104       0.9698               0.0302   \n",
       "11  0.2245    0.3146       0.9690               0.0310   \n",
       "12  0.1717    0.2587       0.9759               0.0241   \n",
       "13  0.1776    0.2660       0.9759               0.0241   \n",
       "\n",
       "    Matthews Correlation Coefficient  \n",
       "0                                NaN  \n",
       "1                             0.1999  \n",
       "2                                NaN  \n",
       "3                             0.1829  \n",
       "4                                NaN  \n",
       "5                             0.2499  \n",
       "6                                NaN  \n",
       "7                             0.2343  \n",
       "8                             0.2860  \n",
       "9                             0.2792  \n",
       "10                            0.2816  \n",
       "11                            0.2839  \n",
       "12                            0.2455  \n",
       "13                            0.2525  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the performance summary\n",
    "print(f\"******************************************\")\n",
    "print(f\"Performance Summary for: {dataset_label}\")\n",
    "print(f\"******************************************\")\n",
    "\n",
    "performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T23:00:45.640759Z",
     "iopub.status.busy": "2024-06-10T23:00:45.639782Z",
     "iopub.status.idle": "2024-06-10T23:00:45.645701Z",
     "shell.execute_reply": "2024-06-10T23:00:45.644433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Execution Time 468.54 seconds:\n"
     ]
    }
   ],
   "source": [
    "print(f\"Completed: Execution Time %s seconds:\" % round((time.time() - start_time),2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusions\n",
    "\n",
    "- A first glance at the summary, it appears that the Boosting models may have performed well with test/train scores were >.8 and similar in scale (<.02 delta).  However, the poor test confusion matrix and balanced accuracy highlight the overfitting.\n",
    "\n",
    "- The Base Cleaned data is overfit as indicated by:\n",
    "    - Poor confusion matrix on the detailed report for test sets on all models\n",
    "    - Low balanced accuracy as compared to the model score (less than 50%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
