{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Analysis\n",
    "\n",
    "- This file differs from [2_data_analysis_1_base_data.ipynb](2_data_analysis_1_base_data.ipynb) in that it:\n",
    "    - scales the base cleaned data created in [1_data_cleaning.ipynb](1_data_cleaning.ipynb).\n",
    "\n",
    "Source dataset: 247076 rows × 37 columns\n",
    "Processed and analyzed dataset: 247076 rows × 37 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:26.188251Z",
     "iopub.status.busy": "2024-06-10T05:57:26.187822Z",
     "iopub.status.idle": "2024-06-10T05:57:27.541339Z",
     "shell.execute_reply": "2024-06-10T05:57:27.539824Z"
    }
   },
   "outputs": [],
   "source": [
    "# package imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import config\n",
    "\n",
    "sys.path.insert(1, config.package_path)\n",
    "import ml_analysis as mlanlys\n",
    "import ml_clean_feature as mlclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read the cleaned dataset from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:27.548970Z",
     "iopub.status.busy": "2024-06-10T05:57:27.547503Z",
     "iopub.status.idle": "2024-06-10T05:57:27.576152Z",
     "shell.execute_reply": "2024-06-10T05:57:27.574671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:                        2015\n",
      "Clean File:                  data/brfss_2015_clean.parquet.gzip\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to Config Settings\n",
    "importlib.reload(config)\n",
    "\n",
    "# BE SURE TO UPDATE THE LABEL FOR THIS ANALYSIS\n",
    "# #############################\n",
    "dataset_label = '2.0 StandardScaler Dataset'\n",
    "# #############################\n",
    "\n",
    "year                        = config.year\n",
    "\n",
    "clean_file                  = config.clean_file\n",
    "\n",
    "print(f\"Year:                        {year}\")\n",
    "print(f\"Clean File:                  {clean_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minmax_scaled.pkl',\n",
       " 'sb_cluster_scaled.pkl',\n",
       " 'sb_random_oversample_scaled.pkl',\n",
       " 'sb_random_undersample_scaled.pkl',\n",
       " 'sb_smoteenn_scaled.pkl',\n",
       " 'sb_smote_scaled.pkl',\n",
       " 'scaled.pkl',\n",
       " 'standard_scaled.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data_path = config.prepared_data_path\n",
    "os.listdir(prepared_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:27.581205Z",
     "iopub.status.busy": "2024-06-10T05:57:27.580708Z",
     "iopub.status.idle": "2024-06-10T05:57:28.002534Z",
     "shell.execute_reply": "2024-06-10T05:57:28.000756Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read final cleaned dataset from parquet file\n",
    "df = pd.read_parquet(clean_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:28.007803Z",
     "iopub.status.busy": "2024-06-10T05:57:28.007328Z",
     "iopub.status.idle": "2024-06-10T05:57:28.014325Z",
     "shell.execute_reply": "2024-06-10T05:57:28.012708Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes_labels = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:28.020344Z",
     "iopub.status.busy": "2024-06-10T05:57:28.019831Z",
     "iopub.status.idle": "2024-06-10T05:57:28.033532Z",
     "shell.execute_reply": "2024-06-10T05:57:28.031784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare the dataset for analysis\n",
    "\n",
    "- Split the dataset into features and labels.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options\n",
    "\n",
    "    operation_dict = {  'target_column'    : 'diabetes',\n",
    "                        'convert_to_binary':  True,\n",
    "                        'scaler'           : 'standard', # options: none, standard, minmax\n",
    "                        'random_sample'    : 'none'      # options: none, undersample, oversample, cluster, smote, smoteenn\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:28.039092Z",
     "iopub.status.busy": "2024-06-10T05:57:28.038625Z",
     "iopub.status.idle": "2024-06-10T05:57:28.086642Z",
     "shell.execute_reply": "2024-06-10T05:57:28.085125Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'diabetes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 StandardScaler \n",
    "- Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  False\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  none\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:190260, y_train:190260, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 160371   1:  3457\n",
      "ValueCounts:   y_test : len:2   0:  53332   1:  1174\n",
      "\n",
      "Before write: lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    160371\n",
      "2.0     26432\n",
      "1.0      3457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    53332\n",
      "2.0     8914\n",
      "1.0     1174\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_standard\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  False,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'none'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 MinMaxScaler\n",
    "- MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  False\n",
      "**Operation:scaler  minmax\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing MinMaxScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  none\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:190260, y_train:190260, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 160403   1:  3476\n",
      "ValueCounts:   y_test : len:2   0:  53300   1:  1155\n",
      "\n",
      "Before write: lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    160403\n",
      "2.0     26381\n",
      "1.0      3476\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    53300\n",
      "2.0     8965\n",
      "1.0     1155\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_minmax\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  False,\n",
    "                    'scaler'            : 'minmax', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'none'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Binary\n",
    "- Convert target from 0/1/2 (No Diabetes/Pre-Diabetes/Diabetes) to 0/1 values  (No Diabetes/Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  none\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "**Operation:random_sample  none\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:190260, y_train:190260, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 163556   1: 26704\n",
      "ValueCounts:   y_test : len:2   0:  54778   1:  8642\n",
      "\n",
      "Before write: lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "Types: X_Trn: <class 'pandas.core.frame.DataFrame'>  X_Tst: <class 'pandas.core.frame.DataFrame'>  y_Trn: <class 'pandas.core.series.Series'>  r_Tst <class 'pandas.core.series.Series'>\n",
      "After write:  lengths:  X_Trn: 190260  X_Tst: 63420  y_Trn: 190260 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    163556\n",
      "1.0     26704\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54778\n",
      "1.0     8642\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_binary\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'none', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'none'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"Types: X_Trn: {type(X_Trn)}  X_Tst: {type(X_Tst)}  y_Trn: {type(y_Trn)}  r_Tst {type(y_Tst)}\")\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 RandomOverSampler\n",
    "- Standard Scaler\n",
    "- Binary\n",
    "- RandomOverSampler sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  oversample\n",
      "  -- Performing RandomOverSampler on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:327292, y_train:327292, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 163646   1:163646\n",
      "ValueCounts:   y_test : len:2   0:  54688   1:  8732\n",
      "\n",
      "Before write: lengths:  X_Trn: 327292  X_Tst: 63420  y_Trn: 327292 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 327292  X_Tst: 63420  y_Trn: 327292 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    163646\n",
      "1.0    163646\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54688\n",
      "1.0     8732\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_sb_random_oversample\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'oversample'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 RandomUnderSampler\n",
    "- Standard Scaler\n",
    "- Binary\n",
    "- RandomUnderSampler sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  undersample\n",
      "  -- Performing RandomUnderSampler on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:52950, y_train:52950, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0:  26475   1: 26475\n",
      "ValueCounts:   y_test : len:2   0:  54549   1:  8871\n",
      "\n",
      "Before write: lengths:  X_Trn: 52950  X_Tst: 63420  y_Trn: 52950 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 52950  X_Tst: 63420  y_Trn: 52950 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    26475\n",
      "1.0    26475\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54549\n",
      "1.0     8871\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_sb_random_undersample\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'undersample'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 ClusterCentroids\n",
    "- Standard Scaler\n",
    "- Binary\n",
    "- ClusterCentroids sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  cluster\n",
      "  -- Performing ClusterCentroids on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:52968, y_train:52968, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0:  26484   1: 26484\n",
      "ValueCounts:   y_test : len:2   0:  54558   1:  8862\n",
      "\n",
      "Before write: lengths:  X_Trn: 52968  X_Tst: 63420  y_Trn: 52968 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 52968  X_Tst: 63420  y_Trn: 52968 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    26484\n",
      "1.0    26484\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54558\n",
      "1.0     8862\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_sb_cluster\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'cluster'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 SMOTE\n",
    "- Standard Scaler\n",
    "- Binary\n",
    "- SMOTE sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  smote\n",
      "  -- Performing SMOTE on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:327622, y_train:327622, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 163811   1:163811\n",
      "ValueCounts:   y_test : len:2   0:  54523   1:  8897\n",
      "\n",
      "Before write: lengths:  X_Trn: 327622  X_Tst: 63420  y_Trn: 327622 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 327622  X_Tst: 63420  y_Trn: 327622 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "0.0    163811\n",
      "1.0    163811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54523\n",
      "1.0     8897\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_sb_smote\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'smote'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 SMOTEENN\n",
    "- Standard Scaler\n",
    "- Binary\n",
    "- SMOTEENN sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T05:57:28.092549Z",
     "iopub.status.busy": "2024-06-10T05:57:28.092000Z",
     "iopub.status.idle": "2024-06-10T05:57:28.339115Z",
     "shell.execute_reply": "2024-06-10T05:57:28.338254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  smoteenn\n",
      "  -- Performing SMOTEENN on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:254380, y_train:254380, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 108784   1:145596\n",
      "ValueCounts:   y_test : len:2   0:  54586   1:  8834\n",
      "\n",
      "Before write: lengths:  X_Trn: 254380  X_Tst: 63420  y_Trn: 254380 y_Tst: 63420\n",
      "After write:  lengths:  X_Trn: 254380  X_Tst: 63420  y_Trn: 254380 y_Tst: 63420\n",
      "\n",
      "y_train.value_counts diabetes\n",
      "1.0    145596\n",
      "0.0    108784\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y_test.value_counts diabetes\n",
      "0.0    54586\n",
      "1.0     8834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary defining modification to be made to the base dataset\n",
    "prepared_file = config.prepared_data_sb_smoteenn\n",
    "\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'smoteenn'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data\n",
    "print(f\"\\nBefore write: lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "\n",
    "# Save Prepared Data to a file\n",
    "with open(prepared_file, 'wb') as file: pickle.dump(data, file)\n",
    "\n",
    "with open(prepared_file, 'rb') as file: data_prepared = pickle.load(file)\n",
    "\n",
    "X_Trn, X_Tst, y_Trn, y_Tst = data_prepared\n",
    "print(f\"After write:  lengths:  X_Trn: {len(X_Trn)}  X_Tst: {len(X_Tst)}  y_Trn: {len(y_Trn)} y_Tst: {len(y_Tst)}\")\n",
    "print(f\"\\ny_train.value_counts {y_Trn.value_counts()}\")\n",
    "print(f\"\\ny_test.value_counts {y_Tst.value_counts()}\")\n",
    "\n",
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"\\nOriginal Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
