{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Analysis\n",
    "\n",
    "- This file differs from [2_data_analysis_1_base_data.ipynb](2_data_analysis_1_base_data.ipynb) in that it:\n",
    "    - scales the base cleaned data created in [1_data_cleaning.ipynb](1_data_cleaning.ipynb).\n",
    "\n",
    "Source dataset: 247076 rows × 37 columns\n",
    "Processed and analyzed dataset: 247076 rows × 37 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:57:58.398379Z",
     "iopub.status.busy": "2024-06-10T06:57:58.395018Z",
     "iopub.status.idle": "2024-06-10T06:58:02.184564Z",
     "shell.execute_reply": "2024-06-10T06:58:02.177700Z"
    }
   },
   "outputs": [],
   "source": [
    "# package imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import config\n",
    "\n",
    "sys.path.insert(1, '../pkgs')\n",
    "import ml_analysis as mlanlys\n",
    "import ml_clean_feature as mlclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read the cleaned dataset from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:02.196088Z",
     "iopub.status.busy": "2024-06-10T06:58:02.195077Z",
     "iopub.status.idle": "2024-06-10T06:58:02.251689Z",
     "shell.execute_reply": "2024-06-10T06:58:02.245715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:                        2021\n",
      "Clean File:                  data/brfss_2021_clean.parquet.gzip\n",
      "Performance Report:          reports/performance_report.pkl\n",
      "Detailed Performance Report: reports/7_smote_dataset_detailed_performance_report.txt\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to Config Settings\n",
    "importlib.reload(config)\n",
    "\n",
    "# BE SURE TO UPDATE THE LABEL FOR THIS ANALYSIS\n",
    "# #############################\n",
    "dataset_label = '7 SMOTE Dataset'\n",
    "# #############################\n",
    "\n",
    "year                        = config.year\n",
    "\n",
    "clean_file                  = config.clean_file\n",
    "performance_report          = config.performance_report\n",
    "\n",
    "report_path                 = config.report_path\n",
    "file_label                  = dataset_label.lower().replace(' ','_')\n",
    "detailed_performance_report = report_path + file_label + '_detailed_performance_report.txt'\n",
    "\n",
    "print(f\"Year:                        {year}\")\n",
    "print(f\"Clean File:                  {clean_file}\")\n",
    "print(f\"Performance Report:          {performance_report}\")\n",
    "print(f\"Detailed Performance Report: {detailed_performance_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:02.267617Z",
     "iopub.status.busy": "2024-06-10T06:58:02.262149Z",
     "iopub.status.idle": "2024-06-10T06:58:03.263464Z",
     "shell.execute_reply": "2024-06-10T06:58:03.254749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read final cleaned dataset from parquet file\n",
    "df = pd.read_parquet(clean_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:03.272559Z",
     "iopub.status.busy": "2024-06-10T06:58:03.271950Z",
     "iopub.status.idle": "2024-06-10T06:58:03.293939Z",
     "shell.execute_reply": "2024-06-10T06:58:03.287953Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes_labels = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:03.302088Z",
     "iopub.status.busy": "2024-06-10T06:58:03.301644Z",
     "iopub.status.idle": "2024-06-10T06:58:03.328975Z",
     "shell.execute_reply": "2024-06-10T06:58:03.323219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247076, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare the dataset for analysis\n",
    "\n",
    "- Split the dataset into features and labels.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:03.343105Z",
     "iopub.status.busy": "2024-06-10T06:58:03.339082Z",
     "iopub.status.idle": "2024-06-10T06:58:03.458825Z",
     "shell.execute_reply": "2024-06-10T06:58:03.455320Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:03.475095Z",
     "iopub.status.busy": "2024-06-10T06:58:03.474113Z",
     "iopub.status.idle": "2024-06-10T06:58:07.483012Z",
     "shell.execute_reply": "2024-06-10T06:58:07.472522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  smote\n",
      "  -- Performing SMOTE on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (247076, 37)  Data:4, X_train:185307, y_train:185307, X_test:61769, y_test:61769\n",
      "ValueCounts:   y_train: len:2   0: 160487   1: 24820\n",
      "ValueCounts:   y_test : len:2   0:  53556   1:  8213\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "target = 'diabetes'\n",
    "# Dictionary defining modification to be made to the base dataset\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'smote'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:07.500545Z",
     "iopub.status.busy": "2024-06-10T06:58:07.499241Z",
     "iopub.status.idle": "2024-06-10T06:58:07.541795Z",
     "shell.execute_reply": "2024-06-10T06:58:07.537153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (247076, 37)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    208389\n",
      "2.0     33033\n",
      "1.0      5654\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modified Dataframe\n",
      "------------------\n",
      "df_modified.shape: (247076, 37)\n",
      "df_modified[diabetes].value_counts:  diabetes\n",
      "0.0    214043\n",
      "1.0     33033\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"Original Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")\n",
    "\n",
    "print(f\"\\nModified Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df_modified.shape: {df_modified.shape}\")\n",
    "print(f\"df_modified[{target}].value_counts:  {df_modified[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:07.550282Z",
     "iopub.status.busy": "2024-06-10T06:58:07.548743Z",
     "iopub.status.idle": "2024-06-10T06:58:07.595113Z",
     "shell.execute_reply": "2024-06-10T06:58:07.591369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (247076, 37)  Data:4, X_train:320974, y_train:320974, X_test:61769, y_test:61769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    160487\n",
       "1.0    160487\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = data\n",
    "print(f\"Dataframe: {df_modified.shape}  Data:{len(data)}, X_train:{len(X_train)}, y_train:{len(y_train)}, X_test:{len(X_test)}, y_test:{len(y_test)}\")\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:07.603533Z",
     "iopub.status.busy": "2024-06-10T06:58:07.601826Z",
     "iopub.status.idle": "2024-06-10T06:58:07.633740Z",
     "shell.execute_reply": "2024-06-10T06:58:07.627486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    53556\n",
       "1.0     8213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run initial Tests and get k_value\n",
    "\n",
    "**From step 2:**  Data = [X_train_modified, X_test_modified, y_train_modified, y_test]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:07.652022Z",
     "iopub.status.busy": "2024-06-10T06:58:07.650999Z",
     "iopub.status.idle": "2024-06-10T06:58:07.715592Z",
     "shell.execute_reply": "2024-06-10T06:58:07.710344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ml_analysis' from '/mnt/c/ML/DU/repos/projects/project-2/DU-project-2-2015/brfss_2021/../pkgs/ml_analysis.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "# Determine the k_value\n",
    "# mlanlys.knn_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** From the knn plot above, pick a k-value of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Run the Analysis\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Run Times\n",
    "\n",
    "-  Base dataset (247076 rows × 37 columns):\n",
    "\n",
    "| Model | Run Time |\n",
    "| ----- | -------- |\n",
    "| test_model(SVC(kernel='linear'), data)                          | Aborted >35min (Data too large, consider for RandomUndersampling dataset) |\n",
    "| test_model(KNeighborsClassifier(n_neighbors=k_value), data)     | 247.13 seconds |\n",
    "| test_model(tree.DecisionTreeClassifier(), data)                 |   3.89 seconds |\n",
    "| test_model(RandomForestClassifier(), data)                      |  60.94 seconds |\n",
    "| test_model(ExtraTreesClassifier(random_state=1), data)          |  58.54 seconds |\n",
    "| test_model(GradientBoostingClassifier(random_state=1), data)    | 115.21 seconds |\n",
    "| test_model(AdaBoostClassifier(random_state=1), data)            |  11.91 seconds |\n",
    "| test_model(LogisticRegression(), data)                          |   4.90 seconds |\n",
    "| **Total** w/o SVC| 502.52 seconds / **8:23 minutes** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T06:58:07.727656Z",
     "iopub.status.busy": "2024-06-10T06:58:07.724548Z",
     "iopub.status.idle": "2024-06-10T07:25:26.871220Z",
     "shell.execute_reply": "2024-06-10T07:25:26.868479Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload any changes to nlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "k_value = 3\n",
    "\n",
    "#### COMMENT OUT ONE OF THE FOLLOWING SECTIONS\n",
    "\n",
    "## SECTION 1\n",
    "# Capture stdout & stderr into two strings: osc.stdout and osc.stderr that contain the output from the function\n",
    "# -- This allows the output to be printed here or to a file or both.\n",
    "\n",
    "with mlanlys.OutStreamCapture() as osc:\n",
    "    performance_summary = mlanlys.run_classification_models(data, k_value)\n",
    "#    performance_summary = mlanlys.run_classification_models_test(data, k_value)\n",
    "\n",
    "## <OR>\n",
    "## SECTION 2\n",
    "\n",
    "# performance_summary = mlanlys.run_classification_models(data, k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T07:25:26.888028Z",
     "iopub.status.busy": "2024-06-10T07:25:26.886069Z",
     "iopub.status.idle": "2024-06-10T07:25:26.901218Z",
     "shell.execute_reply": "2024-06-10T07:25:26.898576Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT if using SECTION 1 in the previous step\n",
    "# print(osc.stdout)\n",
    "\n",
    "# Add code to print osc.stdout to a file if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.1 Archive Performance Summary\n",
    "\n",
    "- For use in Project-2 Performance Summary Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T07:25:26.921583Z",
     "iopub.status.busy": "2024-06-10T07:25:26.921147Z",
     "iopub.status.idle": "2024-06-10T07:25:26.981258Z",
     "shell.execute_reply": "2024-06-10T07:25:26.978748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file reports/performance_report.pkl exists.\n"
     ]
    }
   ],
   "source": [
    "# performance_summary is a dataframe of performance statistics\n",
    "\n",
    "analysis_perf_summary = { 'dataset_size': list(df.shape), 'report': performance_summary}\n",
    "\n",
    "# Performance_report is a file containing all the performance summary statistics\n",
    "if os.path.exists(performance_report):\n",
    "    print(f\"The file {performance_report} exists.\")\n",
    "    # Load Performance Report\n",
    "    with open(performance_report, 'rb') as file: perf_report = pickle.load(file)\n",
    "else:\n",
    "    print(f\"The file {performance_report} does not exist.\")\n",
    "    perf_report = {}\n",
    "    \n",
    "perf_report[dataset_label] = analysis_perf_summary\n",
    "\n",
    "# Save Performance Report\n",
    "with open(performance_report, 'wb') as file: pickle.dump(perf_report, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Archive the Performance Detailed Statistics Report\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T07:25:26.986977Z",
     "iopub.status.busy": "2024-06-10T07:25:26.986566Z",
     "iopub.status.idle": "2024-06-10T07:25:27.021221Z",
     "shell.execute_reply": "2024-06-10T07:25:27.019842Z"
    }
   },
   "outputs": [],
   "source": [
    "# osc.stdout contains the details of the performance statistics\n",
    "\n",
    "with open(detailed_performance_report, \"w\") as file:\n",
    "    file.write(osc.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Performance Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T07:25:27.031659Z",
     "iopub.status.busy": "2024-06-10T07:25:27.031243Z",
     "iopub.status.idle": "2024-06-10T07:25:27.062700Z",
     "shell.execute_reply": "2024-06-10T07:25:27.060614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "Performance Summary for: 7 SMOTE Dataset\n",
      "******************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>slice</th>\n",
       "      <th>score</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.928287</td>\n",
       "      <td>0.928287</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>[[137608, 22879], [139, 160348]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.731160</td>\n",
       "      <td>0.656112</td>\n",
       "      <td>0.697605</td>\n",
       "      <td>[[40614, 12942], [3664, 4549]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[160487, 0], [0, 160487]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.800110</td>\n",
       "      <td>0.598097</td>\n",
       "      <td>0.598097</td>\n",
       "      <td>[[46770, 6786], [5561, 2652]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[160487, 0], [0, 160487]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.592779</td>\n",
       "      <td>0.820380</td>\n",
       "      <td>[[51541, 2015], [6380, 1833]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[160487, 0], [0, 160487]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.862002</td>\n",
       "      <td>0.604151</td>\n",
       "      <td>0.815276</td>\n",
       "      <td>[[51168, 2388], [6136, 2077]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.903914</td>\n",
       "      <td>0.903914</td>\n",
       "      <td>0.968172</td>\n",
       "      <td>[[147491, 12996], [17845, 142642]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.847739</td>\n",
       "      <td>0.653036</td>\n",
       "      <td>0.821124</td>\n",
       "      <td>[[49179, 4377], [5028, 3185]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.864833</td>\n",
       "      <td>0.864833</td>\n",
       "      <td>0.947038</td>\n",
       "      <td>[[135963, 24524], [18861, 141626]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.805242</td>\n",
       "      <td>0.691927</td>\n",
       "      <td>0.804192</td>\n",
       "      <td>[[45324, 8232], [3798, 4415]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.762155</td>\n",
       "      <td>0.762155</td>\n",
       "      <td>0.836941</td>\n",
       "      <td>[[116926, 43561], [32781, 127706]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.733475</td>\n",
       "      <td>0.745277</td>\n",
       "      <td>0.821358</td>\n",
       "      <td>[[39053, 14503], [1960, 6253]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  slice     score  balanced_accuracy  \\\n",
       "0         KNeighborsClassifier  Train  0.928287           0.928287   \n",
       "1         KNeighborsClassifier   Test  0.731160           0.656112   \n",
       "2       DecisionTreeClassifier  Train  1.000000           1.000000   \n",
       "3       DecisionTreeClassifier   Test  0.800110           0.598097   \n",
       "4       RandomForestClassifier  Train  1.000000           1.000000   \n",
       "5       RandomForestClassifier   Test  0.864090           0.592779   \n",
       "6         ExtraTreesClassifier  Train  1.000000           1.000000   \n",
       "7         ExtraTreesClassifier   Test  0.862002           0.604151   \n",
       "8   GradientBoostingClassifier  Train  0.903914           0.903914   \n",
       "9   GradientBoostingClassifier   Test  0.847739           0.653036   \n",
       "10          AdaBoostClassifier  Train  0.864833           0.864833   \n",
       "11          AdaBoostClassifier   Test  0.805242           0.691927   \n",
       "12          LogisticRegression  Train  0.762155           0.762155   \n",
       "13          LogisticRegression   Test  0.733475           0.745277   \n",
       "\n",
       "    roc_auc_score                    confusion_matrix  \\\n",
       "0        0.999013    [[137608, 22879], [139, 160348]]   \n",
       "1        0.697605      [[40614, 12942], [3664, 4549]]   \n",
       "2        1.000000          [[160487, 0], [0, 160487]]   \n",
       "3        0.598097       [[46770, 6786], [5561, 2652]]   \n",
       "4        1.000000          [[160487, 0], [0, 160487]]   \n",
       "5        0.820380       [[51541, 2015], [6380, 1833]]   \n",
       "6        1.000000          [[160487, 0], [0, 160487]]   \n",
       "7        0.815276       [[51168, 2388], [6136, 2077]]   \n",
       "8        0.968172  [[147491, 12996], [17845, 142642]]   \n",
       "9        0.821124       [[49179, 4377], [5028, 3185]]   \n",
       "10       0.947038  [[135963, 24524], [18861, 141626]]   \n",
       "11       0.804192       [[45324, 8232], [3798, 4415]]   \n",
       "12       0.836941  [[116926, 43561], [32781, 127706]]   \n",
       "13       0.821358      [[39053, 14503], [1960, 6253]]   \n",
       "\n",
       "                                classification_report  \n",
       "0                 precision    recall  f1-score   ...  \n",
       "1                 precision    recall  f1-score   ...  \n",
       "2                 precision    recall  f1-score   ...  \n",
       "3                 precision    recall  f1-score   ...  \n",
       "4                 precision    recall  f1-score   ...  \n",
       "5                 precision    recall  f1-score   ...  \n",
       "6                 precision    recall  f1-score   ...  \n",
       "7                 precision    recall  f1-score   ...  \n",
       "8                 precision    recall  f1-score   ...  \n",
       "9                 precision    recall  f1-score   ...  \n",
       "10                precision    recall  f1-score   ...  \n",
       "11                precision    recall  f1-score   ...  \n",
       "12                precision    recall  f1-score   ...  \n",
       "13                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the performance summary\n",
    "print(f\"******************************************\")\n",
    "print(f\"Performance Summary for: {dataset_label}\")\n",
    "print(f\"******************************************\")\n",
    "\n",
    "performance_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusions\n",
    "\n",
    "- A first glance at the summary, it appears that the Boosting models may have performed well with test/train scores were >.8 and similar in scale (<.02 delta).  However, the poor test confusion matrix and balanced accuracy highlight the overfitting.\n",
    "\n",
    "- The Base Cleaned data is overfit as indicated by:\n",
    "    - Poor confusion matrix on the detailed report for test sets on all models\n",
    "    - Low balanced accuracy as compared to the model score (less than 50%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
