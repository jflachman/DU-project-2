{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Analysis\n",
    "\n",
    "- This file differs from [2_data_analysis_1_base_data.ipynb](2_data_analysis_1_base_data.ipynb) in that it:\n",
    "    - scales the base cleaned data created in [1_data_cleaning.ipynb](1_data_cleaning.ipynb).\n",
    "\n",
    "Source dataset: 247076 rows × 37 columns\n",
    "Processed and analyzed dataset: 247076 rows × 37 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "sys.path.insert(1, 'pkgs')\n",
    "import ml_analysis as mlanlys\n",
    "import ml_clean_feature as mlclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read the cleaned dataset from file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to results\n",
    "year = 2015\n",
    "source_path     = \"data/\"\n",
    "clean_file      = source_path + 'brfss_' + str(year) + '_clean.parquet.gzip'\n",
    "\n",
    "report_path = 'reports/'\n",
    "performance_report = report_path + 'performance_report.pkl'\n",
    "\n",
    "# BE SURE TO UPDATE THE LABEL FOR THIS ANALYSIS\n",
    "dataset_label = 'RandomUndersampled Dataset'\n",
    "\n",
    "file_label = dataset_label.lower().replace(' ','_')\n",
    "\n",
    "detailed_performance_report = report_path + file_label + '_detailed_performance_report.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read final cleaned dataset from parquet file\n",
    "df = pd.read_parquet(clean_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_labels = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare the dataset for analysis\n",
    "\n",
    "- Split the dataset into features and labels.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Dataset Modifications in Process\n",
      "-------------------------------------\n",
      "**Operation:target_column  diabetes\n",
      "**Operation:convert_to_binary  True\n",
      "  -- Converting dataset to binary (0,1) from (0,1,2)\n",
      "\n",
      "\n",
      "****Cleaning Feature: diabetes\n",
      "  Initial Unique features in [diabetes]:  [0. 1. 2.]\n",
      "  values_to_drop: ********* NO Parameters were specified *********\n",
      "  translate: {1: 0, 2: 1}\n",
      "  scale: ********* NO Parameters were specified *********\n",
      "  FINAL Unique features in [diabetes]:  [0. 1.]\n",
      "**Operation:scaler  standard\n",
      "  -- Performing train_test_split on dataframe with target:'diabetes'\n",
      "     -- Run automatically before scalar or random_sample operations\n",
      "  -- Performing StandardScaler on X_train: Updates X_train, y_test\n",
      "**Operation:random_sample  undersample\n",
      "  -- Performing RandomUnderSampler on X_train, y_train: Updates X_train, y_train\n",
      "\n",
      "Dataframe, Train Test Summary\n",
      "-----------------------------\n",
      "Dataframe: (253680, 22)  Data:4, X_train:190260, y_train:190260, X_test:63420, y_test:63420\n",
      "ValueCounts:   y_train: len:2   0: 163703   1: 26557\n",
      "ValueCounts:   y_test : len:2   0:  54631   1:  8789\n"
     ]
    }
   ],
   "source": [
    "# reload any changes to mlanlys\n",
    "importlib.reload(mlanlys)\n",
    "\n",
    "target = 'diabetes'\n",
    "# Dictionary defining modification to be made to the base dataset\n",
    "operation_dict = {  'target_column'     :  target,\n",
    "                    'convert_to_binary' :  True,\n",
    "                    'scaler'            : 'standard', # options: none, standard, minmax\n",
    "                    'random_sample'     : 'undersample'      # options: none, undersample, oversample\n",
    "                    }\n",
    "\n",
    "# This insures that df if not modified during the call to modify_base_dataset()\n",
    "df_modified = df.copy()\n",
    "\n",
    "# Modify the base dataset\n",
    "# data is returned where: X_train, X_test, y_train, y_test = data\n",
    "data = mlanlys.modify_base_dataset(df_modified, operation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe\n",
      "------------------\n",
      "df.shape: (253680, 22)\n",
      "df[diabetes].value_counts:  diabetes\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modified Dataframe\n",
      "------------------\n",
      "df_modified.shape: (253680, 22)\n",
      "df_modified[diabetes].value_counts:  diabetes\n",
      "0.0    218334\n",
      "1.0     35346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the original df and the modified dataframe\n",
    "print(f\"Original Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "print(f\"df[{target}].value_counts:  {df[target].value_counts()}\")\n",
    "\n",
    "print(f\"\\nModified Dataframe\")\n",
    "print(f\"------------------\")\n",
    "print(f\"df_modified.shape: {df_modified.shape}\")\n",
    "print(f\"df_modified[{target}].value_counts:  {df_modified[target].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (253680, 22)  Data:4, X_train:53114, y_train:53114, X_test:63420, y_test:63420\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = data\n",
    "print(f\"Dataframe: {df_modified.shape}  Data:{len(data)}, X_train:{len(X_train)}, y_train:{len(y_train)}, X_test:{len(X_test)}, y_test:{len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    26557\n",
       "1.0    26557\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0.0    54631\n",
       "1.0     8789\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Optimization\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.1 Pre-optimization metric results\n",
    "\n",
    "- The summary report of the metrics for all pre-optimization runs is here:  [performance_report.txt](reports/performance_report.txt)\n",
    "- The details of the runs are contained in these file:\n",
    "    - [base_dataset_detailed_performance_report.txt](reports/base_dataset_detailed_performance_report.txt)\n",
    "    - [binary_dataset_detailed_performance_report.txt](reports/binary_dataset_detailed_performance_report.txt)\n",
    "    - [minmax_scaled_dataset_detailed_performance_report.txt](reports/minmax_scaled_dataset_detailed_performance_report.txt)\n",
    "    - [randomoversample_dataset_detailed_performance_report.txt](reports/randomoversample_dataset_detailed_performance.txt)\n",
    "    - [cluster_dataset_detailed_performance_report.txt](reports/cluster_dataset_detailed_performance_report.txt)\n",
    "    - [randomundersampled_dataset_detailed_performance_report.txt](reports/randomundersampled_dataset_detailed_performance_report.txt)\n",
    "    - [minmax_scaled_dataset_detailed_performance_report.txt](reports/minmax_scaled_dataset_detailed_performance_report.txt)\n",
    "    - [smoteen_dataset_detailed_performance_report.txt](reports/smoteen_dataset_detailed_performance_report.txt)\n",
    "    - [standard_scaled_dataset_detailed_performance_report.txt](reports/standard_scaled_dataset_detailed_performance_report.txt)\n",
    "    - [smote_dataset_detailed_performance_report.txt](reports/smote_dataset_detailed_performance_report.txt)\n",
    "\n",
    "#### 3.2 Optimization Dataset used\n",
    "\n",
    "**Note:**  Modify the dataset as desired in Section 2.\n",
    "<br><br>\n",
    "Currently the dataset uses the Base dataset for 2015 with the following modifications:\n",
    "- **Target converted to Binary**:  (0,1) from (0,1,2).\n",
    "    - Base:  0: No diabetes, 1: Pre-diabetes, 2: have diabetes\n",
    "    - binary: 0: No diabetes/pre-diabetes, 1: have diabetes\n",
    "- Scaled the data with **StandardScaler**\n",
    "- Resampled the data with **RandomUnderSampler**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:  Modify the dataset as desired in Section 2.\n",
    "# Currently the dataset uses the Base dataset for 2015 with the following modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lens, X_train:53114, y_train:53114, X_test:63420, y_test:63420\n",
      "y_train value_counts: diabetes\n",
      "0.0    26557\n",
      "1.0    26557\n",
      "Name: count, dtype: int64\n",
      "y_test value_counts: diabetes\n",
      "0.0    54631\n",
      "1.0     8789\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary:\n",
    "X_train, X_test, y_train, y_test = data\n",
    "print(f\"Dataset Lens, X_train:{len(X_train)}, y_train:{len(y_train)}, X_test:{len(X_test)}, y_test:{len(y_test)}\")\n",
    "print(f\"y_train value_counts: {y_train.value_counts()}\")\n",
    "print(f\"y_test value_counts: {y_test.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Perform Optimization:\n",
    "\n",
    "- Datamodel:  ABC\n",
    "- Optimization approach: XYZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Conclusions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Notes: Examples\n",
    "---\n",
    "---\n",
    "\n",
    "Starter Code Below.  Delete once 3.2.1 is completed\n",
    "\n",
    "- See Class example:  **module 14, day 3, activity 2**: hypoerparameters_solution.ipynb\n",
    "- See Class example:  **module 14, day 3, activity 5**: fourth_model_solution.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "# Create the grid search estimator along with a parameter object containing the values to adjust.\n",
    "# Try adjusting n_neighbors with values of 1 through 19. Adjust leaf_size by using 10, 50, 100, and 500.\n",
    "# Include both uniform and distance options for weights.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [10, 50, 100, 500]\n",
    "}\n",
    "grid_clf = GridSearchCV(grid_tuned_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the KNN model and try each combination of parameters.\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the best model\n",
    "grid_y_pred = grid_clf.predict(X_test)\n",
    "print(classification_report(y_test, grid_y_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3\n",
    "# Create the parameter object for the randomized search estimator.\n",
    "# Try adjusting n_neighbors with values of 1 through 19. \n",
    "# Adjust leaf_size by using a range from 1 to 500.\n",
    "# Include both uniform and distance options for weights.\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1,20,2),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': np.arange(1, 500)\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the randomized search estimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_clf = RandomizedSearchCV(random_tuned_model, param_grid, random_state=0, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model by using the randomized search estimator.\n",
    "random_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(random_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "random_tuned_pred = random_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the classification report\n",
    "print(classification_report(y_test, random_tuned_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 3\n",
    "\n",
    "---\n",
    "\n",
    "E3.1 Compute max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "models = {'train_score': [], 'test_score': [], 'max_depth': []}\n",
    "\n",
    "for depth in range(1,10):\n",
    "    models['max_depth'].append(depth)\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=depth)\n",
    "    model.fit(X_train_pca, y_train_encoded)\n",
    "    y_test_pred = model.predict(X_test_pca)\n",
    "    y_train_pred = model.predict(X_train_pca)\n",
    "\n",
    "    models['train_score'].append(balanced_accuracy_score(y_train_encoded, y_train_pred))\n",
    "    models['test_score'].append(balanced_accuracy_score(y_test_encoded, y_test_pred))\n",
    "\n",
    "models_df = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.plot(x='max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.2 Compute n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'train_score': [], 'test_score': [], 'n_estimators': []}\n",
    "\n",
    "for n in [50, 100, 500, 1000]:\n",
    "    models['n_estimators'].append(n)\n",
    "    model = RandomForestClassifier(n_estimators=n, max_depth=7)\n",
    "    model.fit(X_train_pca, y_train_encoded)\n",
    "    y_test_pred = model.predict(X_test_pca)\n",
    "    y_train_pred = model.predict(X_train_pca)\n",
    "\n",
    "    models['train_score'].append(balanced_accuracy_score(y_train_encoded, y_train_pred))\n",
    "    models['test_score'].append(balanced_accuracy_score(y_test_encoded, y_test_pred))\n",
    "\n",
    "models_df = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.plot(x='n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best depth and estimators\n",
    "mdepth = 7\n",
    "nestimators = 1000\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000, max_depth=7)\n",
    "model.fit(X_train_pca, y_train_encoded)\n",
    "y_test_pred = model.predict(X_test_pca)\n",
    "y_train_pred = model.predict(X_train_pca)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train_encoded, y_train_pred)}\")\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_test_encoded, y_test_pred)}\")\n",
    "\n",
    "# print classificaiton report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
